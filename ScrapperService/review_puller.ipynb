{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9aad47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: Options in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (1.4.10)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: chainmap~=1.0.3 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from Options) (1.0.3)\n",
      "Requirement already satisfied: combomethod~=1.0.12 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from Options) (1.0.12)\n",
      "Requirement already satisfied: nulltype~=2.3.1 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from Options) (2.3.1)\n",
      "Requirement already satisfied: six~=1.12.0 in /home/conite/.pyenv/versions/3.11.0/lib/python3.11/site-packages (from Options) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4674b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.google.com/maps/search/?api=1&query=Bank%20Rabat%2C%20Morocco', 'https://www.google.com/maps/search/?api=1&query=Bank%20Casablanca%2C%20Morocco', 'https://www.google.com/maps/search/?api=1&query=Bank%20Marrakech%2C%20Morocco']\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "\n",
    "def generate_google_maps_link(address):\n",
    "    base_url = \"https://www.google.com/maps/search/?api=1&query=\"\n",
    "\n",
    "    # Encode the address to be URL safe\n",
    "    url_safe_address = urllib.parse.quote(address)\n",
    "\n",
    "    # Concatenate the base URL and the encoded address\n",
    "    full_url = base_url + url_safe_address\n",
    "\n",
    "    return full_url\n",
    "\n",
    "# Test the function\n",
    "address = [\"Bank Rabat, Morocco\", \"Bank Casablanca, Morocco\", \"Bank Marrakech, Morocco\"]\n",
    "Ville = [\"Rabat\", \"Casablanca\", \"Marrakech\"]\n",
    "link_lise = []\n",
    "for adress in address:\n",
    "    link_lise.append(generate_google_maps_link(adress))\n",
    "print(link_lise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d57384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.actions.wheel_input import ScrollOrigin\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# DATA CASE 1\n",
    "country     = \"Marrakech\"\n",
    "filename    = \"data_\"+country\n",
    "#link        = link_lise[0]\n",
    "banks_name  = []\n",
    "banks_info  = []\n",
    "full_review = []\n",
    "verbose     = False\n",
    "\n",
    "# UTILS\n",
    "class Utils:\n",
    "    @staticmethod\n",
    "    def is_phone_number(text):\n",
    "        phone_pattern = re.compile(r\"^\\+?\\d[\\d\\s-]{8,}\\d$\")\n",
    "        return bool(phone_pattern.match(text))\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_website_url(text):\n",
    "        url_pattern = re.compile(\n",
    "            r'^(https?:\\/\\/)?'\n",
    "            r'([\\da-z\\.-]+)\\.' \n",
    "            r'([a-z\\.]{2,6})' \n",
    "            r'([\\/\\w \\.-]*)*\\/?$'\n",
    "        )\n",
    "        return bool(url_pattern.match(text))\n",
    "\n",
    "def primary_search(browser):\n",
    "    action = ActionChains(browser)\n",
    "    a = browser.find_elements(By.CLASS_NAME, \"hfpxzc\")\n",
    "    \n",
    "    last_len = len(a)\n",
    "    same_len_count = 0\n",
    "    \n",
    "    while True:\n",
    "        # Scroll down to the last element\n",
    "\n",
    "        try:\n",
    "            scroll_origin = ScrollOrigin.from_element(a[-1])\n",
    "            action.scroll_from_origin(scroll_origin, 0, 1000).perform()\n",
    "            time.sleep(2)  # Wait for new results to load\n",
    "          \n",
    "            a = browser.find_elements(By.CLASS_NAME, \"hfpxzc\")\n",
    "            \n",
    "            if len(a) == last_len:\n",
    "                same_len_count += 1\n",
    "                if same_len_count > 5:\n",
    "                    break\n",
    "            else:\n",
    "                last_len = len(a)\n",
    "                same_len_count = 0\n",
    "        except StaleElementReferenceException:\n",
    "            print(\"StaleElementReferenceException occurred. Retrying...\")\n",
    "            continue\n",
    "\n",
    "    return a, action\n",
    "\n",
    "def throw_error(e):\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "def extract_review(browser, action):\n",
    "    # Click on \"review button\"\n",
    "    try:\n",
    "        tab_action = browser.find_elements(By.CLASS_NAME, \"hh2c6\")\n",
    "        if tab_action == None or len(tab_action) < 2:\n",
    "            return []\n",
    "        advice_btn = tab_action[1]\n",
    "        action.move_to_element(advice_btn).click().perform()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        throw_error(e)\n",
    "\n",
    "    # Scroll down until no more data is loading while loading reviews\n",
    "    reviews_blocs = browser.find_elements(By.CLASS_NAME, \"jJc9Ad\") \n",
    "    last_reviews_count = len(reviews_blocs)\n",
    "    if verbose:\n",
    "        print(last_reviews_count)\n",
    "    _same = 0\n",
    "    while True:\n",
    "        scroll_origin = ScrollOrigin.from_element(reviews_blocs[-1])\n",
    "        action.scroll_from_origin(scroll_origin, 0, 1000).perform()\n",
    "        time.sleep(2)\n",
    "        reviews_blocs = browser.find_elements(By.CLASS_NAME, \"jJc9Ad\") \n",
    "\n",
    "        if len(reviews_blocs) == last_reviews_count:\n",
    "            _same += 1\n",
    "            if _same > 3:\n",
    "                break\n",
    "        else:\n",
    "            last_reviews_count = len(reviews_blocs)\n",
    "            _same = 0\n",
    "        \n",
    "    # Extract the reviews\n",
    "    reviews = []\n",
    "    for bloc in reviews_blocs:\n",
    "        html_content = bloc.get_attribute('outerHTML')\n",
    "        html_content = BeautifulSoup(html_content, 'html.parser')\n",
    "        try:\n",
    "            soup = html_content.find('div', {\"class\": \"d4r55\"})\n",
    "            reviewer_name = soup.text\n",
    "            \n",
    "            soup = html_content.findAll('span', {\"class\": \"hCCjke google-symbols NhBTye elGi1d\"})\n",
    "            reviewer_star = len(soup)\n",
    "\n",
    "            soup = html_content.find('span', {\"class\": \"wiI7pd\"})\n",
    "            reviewer_text = soup.text if soup else \"NAN\"\n",
    "\n",
    "            soup = html_content.find('span', {\"class\": \"rsqaWe\"})\n",
    "            reviewer_publish_data = soup.text\n",
    "\n",
    "            soup = html_content.find('span', {\"class\": \"pkWtMe\"})\n",
    "            reviewer_like_reaction = soup.text if soup else 0\n",
    "            \n",
    "            soup = html_content.find('button', {\"class\": \"WEBjve\"})\n",
    "            reviewer_profil_link = soup.attrs.get('data-href')\n",
    "\n",
    "            soup = html_content.findAll('div', {\"class\": \"wiI7pd\"})\n",
    "            if soup != None or len(soup)!=0:\n",
    "                chat = [msg.text for msg in soup]\n",
    "                reviewer_owner_reply = \"**\".join(chat)\n",
    "            else:\n",
    "                reviewer_owner_reply = \"NAN\"\n",
    "\n",
    "            soup = html_content.find('span', {\"class\": \"DZSIDd\"})\n",
    "            reviewer_owner_reply_date = soup.text if soup else \"NAN\"\n",
    "\n",
    "            reviews.append((reviewer_name, reviewer_star, reviewer_text, reviewer_publish_data, reviewer_like_reaction, reviewer_profil_link, reviewer_owner_reply, reviewer_owner_reply_date))\n",
    "        except Exception as e:\n",
    "            throw_error(e)\n",
    "            continue\n",
    "\n",
    "    return reviews\n",
    "\n",
    "def extract(browser, sites, action):\n",
    "    for i in tqdm(range(len(sites))):\n",
    "        try:\n",
    "            scroll_origin = ScrollOrigin.from_element(sites[i])\n",
    "            action.scroll_from_origin(scroll_origin, 0, 100).perform()\n",
    "            action.move_to_element(sites[i]).perform()\n",
    "            if sites[i] is not None:\n",
    "                sites[i].click()\n",
    "            time.sleep(2)\n",
    "        except StaleElementReferenceException:\n",
    "            print(\"StaleElementReferenceException occurred. Retrying...\")\n",
    "            sites = primary_search(browser) \n",
    "            continue\n",
    "        source = browser.page_source\n",
    "        soup = BeautifulSoup(source, 'html.parser')\n",
    "        try:\n",
    "            Name_Html = soup.findAll('h1', {\"class\": \"DUwDvf lfPIob\"})\n",
    "            name = Name_Html[0].text\n",
    "            if name not in banks_name:\n",
    "                # Scrape Bank information\n",
    "                banks_name.append(name)\n",
    "                infos = soup.findAll('div', {\"class\": \"Io6YTe\"})\n",
    "                phone = \"Not available\"\n",
    "                for info in infos:\n",
    "                    if Utils.is_phone_number(info.text):\n",
    "                        phone = info.text\n",
    "                address = infos[0].text if infos else \"Not available\"\n",
    "                website = \"Not available\"\n",
    "                for info in infos:\n",
    "                    if Utils.is_website_url(info.text):\n",
    "                        website = info.text\n",
    "                if verbose:\n",
    "                    print([name, phone, address, website])\n",
    "                bank_details = (name, phone, address, website)\n",
    "                \n",
    "                # Scrape reviews\n",
    "                reviews = extract_review(browser, action)\n",
    "                for i in range(len(reviews)):\n",
    "                    full_review.append(bank_details + reviews[i])\n",
    "\n",
    "                # Save record\n",
    "                df = pd.DataFrame(full_review, columns=['Bank_Name', 'Bank_Phone_number', 'Bank_Address', 'Bank_Website', 'Reviewer_Nane', 'Reviewer_Sart', 'Reviewer_Text', 'Reviewer_Publish_Date', 'Reviewer_Like_Reaction', 'Reviewer_Profil_Link', 'Reviewer_Owner_Reply', 'Reviewer_Owner_Reply_Date'])\n",
    "                df.to_csv(filename + '.csv', index=False, encoding='utf-8')\n",
    "        except Exception as e:\n",
    "            # Alert maintanier\n",
    "            throw_error(e)\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44665463",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'link_lise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ROBOT ON ACTION\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m link_lise:\n\u001b[1;32m      5\u001b[0m     filename    \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mVille[i]\n\u001b[1;32m      6\u001b[0m     chrome_options \u001b[38;5;241m=\u001b[39m Options()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'link_lise' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0 \n",
    "link_lise = [\"Morocco Bank Rabat\", \"Morocco Bank Casablanca\", \"Morocco Bank Marrakech\"]\n",
    "Ville = [\"Rabat\", \"Casablanca\", \"Marrakech\"]\n",
    "# ROBOT ON ACTION\n",
    "for link in link_lise:\n",
    "    filename    = \"data_\"+Ville[i]\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--lang=fr\")\n",
    "    #chrome_options.add_argument(\"--headless\")\n",
    "    browser = webdriver.Chrome(options=chrome_options)\n",
    "    browser.get(link)\n",
    "    time.sleep(10)\n",
    "\n",
    "\n",
    "    sites, action = primary_search(browser)\n",
    "    extract(browser, sites, action)\n",
    "\n",
    "    browser.quit()\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24525fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451551fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500d268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
